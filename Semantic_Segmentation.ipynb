{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_Segmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/TensorFlow_Projects/blob/master/Semantic_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aX0ywofdlCkv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import scipy\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPicUfClNAew",
        "colab_type": "code",
        "outputId": "1c7bd94e-661a-4ba2-8a82-3d4aabcacff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if not tf.test.gpu_device_name():\n",
        "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
        "else:\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8W6c9K7L9jLY",
        "colab_type": "code",
        "outputId": "7577cb14-f458-4fc6-a0ce-b86c1958d4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "siRF6xFEG_O-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w57cDCT89ihy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "image_shape = (160, 576)\n",
        "epochs = 40\n",
        "batch_size = 16\n",
        "dropout = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89HjsYfr-MsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "runs_dir = '/content/drive/My Drive/runs'\n",
        "vgg_path = '/content/drive/My Drive/VGG/VGG/vgg'\n",
        "testing_dir = '/content/drive/My Drive/Road Data/road_data/testing'\n",
        "training_dir = '/content/drive/My Drive/Road Data/road_data/training'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NRPmBkn7CKRD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct_label = tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], num_classes])\n",
        "learning_rate = tf.placeholder(tf.float32)\n",
        "keep_prob = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ca7idY1tL84F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_vgg(sess, vgg_path):\n",
        "  \n",
        "  # load the model and weights\n",
        "  model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n",
        "\n",
        "  # Get Tensors to be returned from graph\n",
        "  graph = tf.get_default_graph()\n",
        "  image_input = graph.get_tensor_by_name('image_input:0')\n",
        "  keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
        "  layer3 = graph.get_tensor_by_name('layer3_out:0')\n",
        "  layer4 = graph.get_tensor_by_name('layer4_out:0')\n",
        "  layer7 = graph.get_tensor_by_name('layer7_out:0')\n",
        "\n",
        "  return image_input, keep_prob, layer3, layer4, layer7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icSBncVyMGXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
        "   \n",
        "    # Use a shorter variable name for simplicity\n",
        "    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
        "\n",
        "    # Apply 1x1 convolution in place of fully connected layer\n",
        "    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name=\"fcn8\")\n",
        "\n",
        "    # Upsample fcn8 with size depth=(4096?) to match size of layer 4 so that we can add skip connection with 4th layer\n",
        "    fcn9 = tf.layers.conv2d_transpose(fcn8, filters=layer4.get_shape().as_list()[-1],\n",
        "    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\")\n",
        "\n",
        "    # Add a skip connection between current final layer fcn8 and 4th layer\n",
        "    fcn9_skip_connected = tf.add(fcn9, layer4, name=\"fcn9_plus_vgg_layer4\")\n",
        "\n",
        "    # Upsample again\n",
        "    fcn10 = tf.layers.conv2d_transpose(fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n",
        "    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\")\n",
        "\n",
        "    # Add skip connection\n",
        "    fcn10_skip_connected = tf.add(fcn10, layer3, name=\"fcn10_plus_vgg_layer3\")\n",
        "\n",
        "    # Upsample again\n",
        "    fcn11 = tf.layers.conv2d_transpose(fcn10_skip_connected, filters=num_classes,\n",
        "    kernel_size=16, strides=(8, 8), padding='SAME', name=\"fcn11\")\n",
        "\n",
        "    return fcn11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cj0ovuBWMQPy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
        "  \n",
        "  # Reshape 4D tensors to 2D, each row represents a pixel, each column a class\n",
        "  logits = tf.reshape(nn_last_layer, (-1, num_classes), name=\"fcn_logits\")\n",
        "  correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes))\n",
        "\n",
        "  # Calculate distance from actual labels using cross entropy\n",
        "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped[:])\n",
        "  # Take mean for total loss\n",
        "  loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\")\n",
        "\n",
        "  # The model implements this operation to find the weights/parameters that would yield correct pixel labels\n",
        "  train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, name=\"fcn_train_op\")\n",
        "\n",
        "  return logits, train_op, loss_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0x3ADWNMY7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op,\n",
        "             cross_entropy_loss, input_image,\n",
        "             correct_label, keep_prob, learning_rate):\n",
        "\n",
        "  keep_prob_value = 0.5\n",
        "  learning_rate_value = 0.001\n",
        "  for epoch in range(epochs):\n",
        "      # Create function to get batches\n",
        "      total_loss = 0\n",
        "      for X_batch, gt_batch in get_batches_fn(batch_size):\n",
        "\n",
        "          loss, _ = sess.run([cross_entropy_loss, train_op],\n",
        "          feed_dict={input_image: X_batch, correct_label: gt_batch,\n",
        "          keep_prob: keep_prob_value, learning_rate:learning_rate_value})\n",
        "\n",
        "          total_loss += loss;\n",
        "\n",
        "      print(\"EPOCH {} ...\".format(epoch + 1))\n",
        "      print(\"Loss = {:.3f}\".format(total_loss))\n",
        "      print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c86G_CJ6GoTr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gen_batch_function(data_folder, image_shape):\n",
        "\t\"\"\"\n",
        "\tGenerate function to create batches of training data\n",
        "\t:param data_folder: Path to folder that contains all the datasets\n",
        "\t:param image_shape: Tuple - Shape of image\n",
        "\t:return:\n",
        "\t\"\"\"\n",
        "\tdef get_batches_fn(batch_size):\n",
        "\t\t\"\"\"\n",
        "\t\tCreate batches of training data\n",
        "\t\t:param batch_size: Batch Size\n",
        "\t\t:return: Batches of training data\n",
        "\t\t\"\"\"\n",
        "\t\t# Grab image and label paths\n",
        "\t\timage_paths = glob(os.path.join(data_folder, 'image_2', '*.png'))\n",
        "\t\tlabel_paths = {\n",
        "\t\t\tre.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
        "\t\t\tfor path in glob(os.path.join(data_folder, 'gt_image_2', '*_road_*.png'))}\n",
        "\t\tbackground_color = np.array([255, 0, 0])\n",
        "\n",
        "\t\t# Shuffle training data\n",
        "\t\trandom.shuffle(image_paths)\n",
        "\t\t# Loop through batches and grab images, yielding each batch\n",
        "\t\tfor batch_i in range(0, len(image_paths), batch_size):\n",
        "\t\t\timages = []\n",
        "\t\t\tgt_images = []\n",
        "\t\t\tfor image_file in image_paths[batch_i:batch_i+batch_size]:\n",
        "\t\t\t\tgt_image_file = label_paths[os.path.basename(image_file)]\n",
        "\t\t\t\t# Re-size to image_shape\n",
        "\t\t\t\timage = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
        "\t\t\t\tgt_image = scipy.misc.imresize(scipy.misc.imread(gt_image_file), image_shape)\n",
        "\n",
        "\t\t\t\t# Create \"one-hot-like\" labels by class\n",
        "\t\t\t\tgt_bg = np.all(gt_image == background_color, axis=2)\n",
        "\t\t\t\tgt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
        "\t\t\t\tgt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
        "\n",
        "\t\t\t\timages.append(image)\n",
        "\t\t\t\tgt_images.append(gt_image)\n",
        "\n",
        "\t\t\tyield np.array(images), np.array(gt_images)\n",
        "\treturn get_batches_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7i-KeXx3xDlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_inference_samples(runs_dir, testing_dir, sess, image_shape, logits, keep_prob, input_image):\n",
        "\t\"\"\"\n",
        "\tSave test images with semantic masks of lane predictions to runs_dir.\n",
        "\t:param runs_dir: Directory to save output images\n",
        "\t:param data_dir: Path to the directory that contains the datasets\n",
        "\t:param sess: TF session\n",
        "\t:param image_shape: Tuple - Shape of image\n",
        "\t:param logits: TF Tensor for the logits\n",
        "\t:param keep_prob: TF Placeholder for the dropout keep probability\n",
        "\t:param input_image: TF Placeholder for the image placeholder\n",
        "\t\"\"\"\n",
        "\t# Make folder for current run\n",
        "\toutput_dir = os.path.join(runs_dir, str(time.time()))\n",
        "\tif os.path.exists(output_dir):\n",
        "\t\tshutil.rmtree(output_dir)\n",
        "\tos.makedirs(output_dir)\n",
        "\n",
        "\t# Run NN on test images and save them to HD\n",
        "\tprint('Training Finished. Saving test images to: {}'.format(output_dir))\n",
        "\timage_outputs = gen_test_output(\n",
        "\t\tsess, logits, keep_prob, input_image, os.path.join(data_dir, 'data_road/testing'), image_shape)\n",
        "\tfor name, image in image_outputs:\n",
        "\t\tscipy.misc.imsave(os.path.join(output_dir, name), image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kq9ZG_gYMjXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    \n",
        "  get_batches_fn = gen_batch_function(training_dir, image_shape)\n",
        "  \n",
        "  with tf.Session() as session:\n",
        "        \n",
        "    image_input, keep_prob, layer3, layer4, layer7 = load_vgg(session, vgg_path)\n",
        "    \n",
        "    model_output = layers(layer3, layer4, layer7, num_classes)\n",
        "\n",
        "    logits, train_op, cross_entropy_loss = optimize(model_output, correct_label, learning_rate, num_classes)\n",
        "    \n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.local_variables_initializer())\n",
        "\n",
        "    print(\"Model build successful, starting training\")\n",
        "\n",
        "    train_nn(session, epochs, batch_size, get_batches_fn, \n",
        "             train_op, cross_entropy_loss, image_input,\n",
        "             correct_label, keep_prob, learning_rate)\n",
        "\n",
        "    #save_inference_samples(runs_dir, testing_dir, session, image_shape, logits, keep_prob, image_input)\n",
        "    \n",
        "    print(\"All done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5oN1T-4h2Gh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "c3685c40-2f02-4a82-c0f5-55f086ae3b20"
      },
      "cell_type": "code",
      "source": [
        "run() "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-519b2e156bc8>:4: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/VGG/VGG/vgg/variables/variables\n",
            "WARNING:tensorflow:From <ipython-input-9-1e56230baf0b>:7: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-9-1e56230baf0b>:11: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d_transpose instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-cfc420833b6f>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Model build successful, starting training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-81f1ea10617b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-b9abd55420f4>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     train_nn(session, epochs, batch_size, get_batches_fn, \n\u001b[1;32m     19\u001b[0m              \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m              correct_label, keep_prob, learning_rate)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#save_inference_samples(runs_dir, testing_dir, session, image_shape, logits, keep_prob, image_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ba93a5c99201>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image, correct_label, keep_prob, learning_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m# Create function to get batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batches_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           loss, _ = sess.run([cross_entropy_loss, train_op],\n",
            "\u001b[0;32m<ipython-input-12-363356931096>\u001b[0m in \u001b[0;36mget_batches_fn\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \t\t\"\"\"\n\u001b[1;32m     14\u001b[0m                 \u001b[0;31m# Grab image and label paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \t\tlabel_paths = {\n\u001b[1;32m     17\u001b[0m                         \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'_(lane|road)_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    }
  ]
}